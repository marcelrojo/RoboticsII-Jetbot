{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a9cdc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "import tf2onnx\n",
    "\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Flatten,\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Dropout,\n",
    "    Input,\n",
    "    BatchNormalization,\n",
    "    Concatenate,\n",
    "    GlobalAveragePooling2D,\n",
    "    Conv2DTranspose,\n",
    "    concatenate,\n",
    ")\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import Sequence, plot_model\n",
    "\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import (\n",
    "    load_img,\n",
    "    img_to_array,\n",
    "    ImageDataGenerator,\n",
    ")\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from typing import Generator\n",
    "\n",
    "import random\n",
    "\n",
    "random_state = 123456\n",
    "random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55f8572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_data(data_frame, window_size=5):\n",
    "\n",
    "    window = 2 * window_size + 1  \n",
    "    return data_frame.rolling(window=window, min_periods=1, center=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37edca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(csv_paths) -> Generator[np.array, float, float]:\n",
    "    for csv_path in csv_paths:\n",
    "        csv_data = pd.read_csv(csv_path, header=None)\n",
    "        csv_data.columns = [\"id\", \"forward\", \"left\"]\n",
    "        \n",
    "        csv_data = smooth_data(csv_data)\n",
    "        \n",
    "        image_paths = glob(f\"{csv_path.removesuffix('.csv')}/*.jpg\")\n",
    "        random.shuffle(image_paths)\n",
    "        \n",
    "        for image_path in image_paths:\n",
    "            image_data = load_img(image_path)\n",
    "            image_number = int(Path(image_path).name.removesuffix(\".jpg\"))\n",
    "            row = csv_data[csv_data[\"id\"]==image_number]\n",
    "            if row.empty:\n",
    "                continue\n",
    "            yield image_data, row[\"forward\"].values[0], row[\"left\"].values[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76b65284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_preprocess(paths, image_size, batch_size):\n",
    "    def preprocess(image, image_size):\n",
    "        image = img_to_array(image).astype(np.uint8)\n",
    "        \n",
    "        image = cv2.resize(image, (image_size, image_size))\n",
    "        \n",
    "        img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        img_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(10, 10)).apply(img_gray)\n",
    "        img_blurred = cv2.GaussianBlur(img_clahe, (3, 3), 0)\n",
    "        \n",
    "        img_crop = cv2.resize(img_blurred, (image_size, image_size))\n",
    "        \n",
    "        pil_image = Image.fromarray(img_crop.astype(np.uint8), \"L\")\n",
    "        \n",
    "        return pil_image\n",
    "    \n",
    "    def augment(image, forward, left):\n",
    "        image_flip = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        left_flipped = -left\n",
    "        forward_flipped = forward\n",
    "        return image_flip, forward_flipped, left_flipped\n",
    "\n",
    "    data_loader = load_data(paths)\n",
    "    batch_images = []\n",
    "    batch_labels = []\n",
    "\n",
    "    for image, forward, left in data_loader:\n",
    "\n",
    "        image = preprocess(image, image_size)\n",
    "        \n",
    "        image_flipped, forward_flipped, left_flipped = augment(image, forward, left)\n",
    "        \n",
    "        image = img_to_array(image).astype(np.float32) / 255.0\n",
    "        image_flipped = img_to_array(image_flipped).astype(np.float32) / 255.0\n",
    "        \n",
    "        batch_images.append(image_flipped)\n",
    "        batch_labels.append([forward_flipped, left_flipped])\n",
    "    \n",
    "        batch_images.append(image)\n",
    "        batch_labels.append([forward, left])\n",
    "\n",
    "        if len(batch_images) == 2 * batch_size:\n",
    "            yield np.array(batch_images), np.array(batch_labels)\n",
    "            batch_images = []\n",
    "            batch_labels = []\n",
    "            \n",
    "    if batch_images:\n",
    "        yield np.array(batch_images), np.array(batch_labels)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d8e41a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_wrapper(paths):\n",
    "    for batch_images, batch_labels in load_data_preprocess(paths, 64, 32):\n",
    "        yield batch_images, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43318ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_paths = glob(\"../dataset/*.csv\")\n",
    "random.shuffle(csv_paths)\n",
    "\n",
    "\n",
    "test_paths = csv_paths[:3]\n",
    "train_val_paths = csv_paths[3:]\n",
    "\n",
    "val_path = train_val_paths[0]        \n",
    "train_paths = train_val_paths[1:] \n",
    "\n",
    "img_size = 64\n",
    "batch_size = 16\n",
    "\n",
    "test_loader = load_data_preprocess(test_paths, img_size, batch_size)\n",
    "train_loader = load_data_preprocess(train_paths, img_size, batch_size)\n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: generator_wrapper(train_paths),\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=([None, 64, 64, 1], [None, 2])\n",
    ").repeat()\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: generator_wrapper([val_path]),\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=([None, 64, 64, 1], [None, 2])\n",
    ").repeat()\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: generator_wrapper(test_paths),\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=([None, 64, 64, 1], [None, 2])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12856913",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_samples = sum(\n",
    "    [sum(1 for _ in load_data_preprocess([path], 64, batch_size)) * batch_size * 2 for path in train_paths]\n",
    ")\n",
    "steps_per_epoch = total_train_samples // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d99e444",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_val_samples = sum(\n",
    "    [sum(1 for _ in load_data_preprocess([path], 64, batch_size)) * batch_size * 2 for path in [val_path]]\n",
    ")\n",
    "val_steps = total_val_samples // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd77d777",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_test_samples = sum(\n",
    "    [sum(1 for _ in load_data_preprocess([path], 64, batch_size)) * batch_size * 2 for path in test_paths]\n",
    ")\n",
    "test_steps = total_test_samples // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2de78e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mse_loss(forward_weight=3.0, left_weight=7.0):\n",
    "    def loss(y_true, y_pred):\n",
    "        forward_true = y_true[:, 0]\n",
    "        left_true = y_true[:, 1]\n",
    "\n",
    "        forward_pred = y_pred[:, 0]\n",
    "        left_pred = y_pred[:, 1]\n",
    "\n",
    "        forward_mse = tf.reduce_mean(tf.square(forward_true - forward_pred))\n",
    "        left_mse = tf.reduce_mean(tf.square(left_true - left_pred))\n",
    "\n",
    "        return forward_weight * forward_mse + left_weight * left_mse\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9da9987e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(image_size):\n",
    "    inputs = Input(shape=(image_size, image_size, 1))\n",
    "    x = Conv2D(16, (3, 3), activation=\"relu\", padding=\"same\",\n",
    "           kernel_regularizer=l2(1e-4))(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64, activation=\"relu\", kernel_regularizer=l2(1e-4))(x)\n",
    "    x = Dropout(0.5)(x)  \n",
    "    x = Dense(32, activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputs = Dense(2, activation=\"tanh\")(x)\n",
    "\n",
    "    return Model(inputs = inputs, outputs = outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f0966e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_forward(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true[:, 0] - y_pred[:, 0]))\n",
    "\n",
    "def mse_left(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true[:, 1] - y_pred[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "065ef75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 64, 64, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 64, 64, 16)        160       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 64, 64, 16)        64        \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 32, 32, 16)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 32)        4640      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 32, 32, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 16, 16, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                524352    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 531490 (2.03 MB)\n",
      "Trainable params: 531394 (2.03 MB)\n",
      "Non-trainable params: 96 (384.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(image_size=img_size)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10ada5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=weighted_mse_loss(forward_weight=2.0, left_weight=3.0),\n",
    "    metrics=['mse', mse_forward, mse_left],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0948c94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-23 18:24:57.122937: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2025-05-23 18:25:01.972961: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f79c83a4540 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-05-23 18:25:01.973060: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2025-05-23 18:25:02.020980: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-05-23 18:25:02.330679: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "598/598 [==============================] - 207s 326ms/step - loss: 2.2144 - mse: 0.3746 - mse_forward: 0.0510 - mse_left: 0.6978 - val_loss: 1.7490 - val_mse: 0.2886 - val_mse_forward: 0.0033 - val_mse_left: 0.5731\n",
      "Epoch 2/20\n",
      "598/598 [==============================] - 164s 275ms/step - loss: 1.3336 - mse: 0.2255 - mse_forward: 0.0423 - mse_left: 0.4083 - val_loss: 0.5892 - val_mse: 0.0956 - val_mse_forward: 0.0097 - val_mse_left: 0.1818\n",
      "Epoch 3/20\n",
      "598/598 [==============================] - 151s 253ms/step - loss: 0.4403 - mse: 0.0750 - mse_forward: 0.0349 - mse_left: 0.1149 - val_loss: 0.6028 - val_mse: 0.0980 - val_mse_forward: 0.0101 - val_mse_left: 0.1858\n",
      "Epoch 4/20\n",
      "598/598 [==============================] - 149s 249ms/step - loss: 0.4076 - mse: 0.0694 - mse_forward: 0.0340 - mse_left: 0.1048 - val_loss: 0.3519 - val_mse: 0.0560 - val_mse_forward: 0.0093 - val_mse_left: 0.1025\n",
      "Epoch 5/20\n",
      "598/598 [==============================] - 165s 276ms/step - loss: 0.3873 - mse: 0.0661 - mse_forward: 0.0345 - mse_left: 0.0975 - val_loss: 0.4143 - val_mse: 0.0664 - val_mse_forward: 0.0099 - val_mse_left: 0.1229\n",
      "Epoch 6/20\n",
      "598/598 [==============================] - 164s 274ms/step - loss: 0.3775 - mse: 0.0642 - mse_forward: 0.0345 - mse_left: 0.0938 - val_loss: 0.4198 - val_mse: 0.0669 - val_mse_forward: 0.0100 - val_mse_left: 0.1239\n",
      "Epoch 7/20\n",
      "598/598 [==============================] - 168s 282ms/step - loss: 0.3626 - mse: 0.0612 - mse_forward: 0.0333 - mse_left: 0.0890 - val_loss: 0.3464 - val_mse: 0.0544 - val_mse_forward: 0.0093 - val_mse_left: 0.0994\n",
      "Epoch 8/20\n",
      "598/598 [==============================] - 171s 287ms/step - loss: 0.3416 - mse: 0.0576 - mse_forward: 0.0334 - mse_left: 0.0817 - val_loss: 0.5204 - val_mse: 0.0830 - val_mse_forward: 0.0100 - val_mse_left: 0.1559\n",
      "Epoch 9/20\n",
      "598/598 [==============================] - 148s 248ms/step - loss: 0.3101 - mse: 0.0519 - mse_forward: 0.0329 - mse_left: 0.0709 - val_loss: 0.3532 - val_mse: 0.0556 - val_mse_forward: 0.0106 - val_mse_left: 0.1008\n",
      "Epoch 10/20\n",
      "598/598 [==============================] - 164s 275ms/step - loss: 0.2635 - mse: 0.0444 - mse_forward: 0.0320 - mse_left: 0.0567 - val_loss: 0.3656 - val_mse: 0.0578 - val_mse_forward: 0.0092 - val_mse_left: 0.1060\n",
      "Epoch 11/20\n",
      "598/598 [==============================] - 171s 287ms/step - loss: 0.2312 - mse: 0.0393 - mse_forward: 0.0318 - mse_left: 0.0468 - val_loss: 0.3889 - val_mse: 0.0619 - val_mse_forward: 0.0102 - val_mse_left: 0.1135\n",
      "Epoch 12/20\n",
      "598/598 [==============================] - 165s 276ms/step - loss: 0.2082 - mse: 0.0355 - mse_forward: 0.0313 - mse_left: 0.0396 - val_loss: 0.4427 - val_mse: 0.0715 - val_mse_forward: 0.0123 - val_mse_left: 0.1307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f7aa97c2550>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=20,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    \n",
    "    validation_steps=val_steps,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81c58ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-23 18:58:36.966862: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-23 18:58:36.967023: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2025-05-23 18:58:36.968331: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2025-05-23 18:58:36.970034: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-23 18:58:36.970224: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-23 18:58:36.970302: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-23 18:58:36.971194: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-23 18:58:36.971210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-05-23 18:58:36.971319: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-23 18:58:36.971389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1767 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2025-05-23 18:58:37.034807: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-23 18:58:37.034929: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-23 18:58:37.035017: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-23 18:58:37.035294: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-23 18:58:37.035331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-05-23 18:58:37.035425: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-23 18:58:37.035472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1767 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2025-05-23 18:58:37.045945: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-23 18:58:37.046010: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2025-05-23 18:58:37.046166: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2025-05-23 18:58:37.046544: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-23 18:58:37.046637: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-23 18:58:37.046710: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-23 18:58:37.046954: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-23 18:58:37.046970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-05-23 18:58:37.047121: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-23 18:58:37.047140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1767 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "spec = (tf.TensorSpec((None, 64, 64, 1), tf.float32, name=\"input\"),)\n",
    "\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ae92431",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models_onnx/model_opset11_new_5w.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "333b0f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 22s 164ms/step - loss: 0.4184 - mse: 0.0714 - mse_forward: 0.0402 - mse_left: 0.1046\n",
      "Test Results:\n",
      "loss: 0.4184\n",
      "mse: 0.0714\n",
      "mse_forward: 0.0402\n",
      "mse_left: 0.1046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-23 18:58:59.623107: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 14099480660540712052\n",
      "2025-05-23 18:58:59.623186: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 15133277849161781160\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_loader, return_dict=True)\n",
    "\n",
    "print(\"Test Results:\")\n",
    "for name, value in results.items():\n",
    "    print(f\"{name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44dce5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "2/2 [==============================] - 0s 22ms/step\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "2/2 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "2/2 [==============================] - 0s 18ms/step\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "2/2 [==============================] - 0s 18ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "2/2 [==============================] - 0s 18ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "2/2 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 21ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "2/2 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "2/2 [==============================] - 0s 19ms/step\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "2/2 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 22ms/step\n",
      "2/2 [==============================] - 0s 21ms/step\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 19ms/step\n",
      "2/2 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 19ms/step\n",
      "2/2 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "2/2 [==============================] - 0s 21ms/step\n",
      "2/2 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Total MSE: 0.0714\n",
      "MSE Forward: 0.0396\n",
      "MSE Left: 0.1033\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Collect the true labels and predictions\n",
    "y_true_list = []\n",
    "y_pred_list = []\n",
    "\n",
    "for batch_x, batch_y in test_dataset.take(test_steps*batch_size):  \n",
    "    preds = model.predict(batch_x)\n",
    "    y_pred_list.append(preds)\n",
    "    y_true_list.append(batch_y.numpy())\n",
    "\n",
    "# Convert lists to arrays\n",
    "y_pred_all = np.vstack(y_pred_list)\n",
    "y_true_all = np.vstack(y_true_list)\n",
    "\n",
    "# Compute total MSE\n",
    "total_mse = mean_squared_error(y_true_all, y_pred_all)\n",
    "\n",
    "# Compute per-output MSE\n",
    "mse_forward = mean_squared_error(y_true_all[:, 0], y_pred_all[:, 0])\n",
    "mse_left = mean_squared_error(y_true_all[:, 1], y_pred_all[:, 1])\n",
    "\n",
    "print(f\"Total MSE: {total_mse:.4f}\")\n",
    "print(f\"MSE Forward: {mse_forward:.4f}\")\n",
    "print(f\"MSE Left: {mse_left:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
